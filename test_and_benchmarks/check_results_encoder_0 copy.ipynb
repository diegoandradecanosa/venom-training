{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rtx3090/Disco2TB/roberto.lopez/anaconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/media/rtx3090/Disco2TB/roberto.lopez/anaconda3/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:347: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://spcl.github.io/dace-webclient/dist/sdfv.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statistics\n",
    "import torch\n",
    "import timeit\n",
    "import argparse\n",
    "\n",
    "import spatha\n",
    "import sten\n",
    "\n",
    "from grouped_nmv_tensor import VenomTensor, venom_mask_sparsify\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/roberto.lopez/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using cache found in /home/roberto.lopez/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using cache found in /home/roberto.lopez/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "v = 128\n",
    "n = 2\n",
    "m = 8\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "sparse_model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-large-uncased')\n",
    "masked_sparse_model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-large-uncased')\n",
    "dense_model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-large-uncased').to(device='cuda:0').half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VenomSparsifier:\n",
    "    def __init__(self, n, m, v):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.v = v\n",
    "\n",
    "    @staticmethod\n",
    "    def get_random_mask(tensor, m, v):\n",
    "        mask = torch.zeros(tensor.shape, dtype=tensor.dtype)\n",
    "        m_tmp = torch.cat( (torch.tensor([1,0,1,0]), torch.zeros(m-4)), 0 )\n",
    "        mask = mask.reshape(-1, v, m) + m_tmp\n",
    "        mask = mask.reshape(tensor.shape)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def __call__(self, tensor, grad_fmt=None):\n",
    "        # random pruning (cuSparseLt-like approach) -> mask, columns\n",
    "        nrows, ncols = tensor.shape\n",
    "        columns = torch.zeros(nrows//self.v, ncols//self.m*4, dtype=torch.int32)\n",
    "        columns = columns.reshape((-1,4)) + torch.tensor([0,1,2,3], dtype=torch.int32)\n",
    "        columns = columns.reshape((nrows//self.v, ncols//self.m*4))\n",
    "\n",
    "        mask = VenomSparsifier.get_random_mask(tensor, self.m, self.v)\n",
    "\n",
    "        sparse_mtx = sten.SparseTensorWrapper.wrapped_from_dense(\n",
    "            VenomTensor(self.n, self.m, self.v, tensor, mask, columns, tensor.device),\n",
    "            tensor,\n",
    "            grad_fmt,\n",
    "        )\n",
    "\n",
    "        return sparse_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dense_mul_dispatch(sparse_values, sparse_indices, sparse_metadata, dense, nrows_sp, ncols_sp, ncols_d, m, n, v, nnz, bias):\n",
    "\n",
    "    dense_ = dense.contiguous()\n",
    "\n",
    "    output = spatha.spmm_128x64x32_32x64x32_16x8x32_2(\n",
    "                          sparse_metadata.to(device='cuda:0'),  # metadata\n",
    "                          sparse_indices.to(device='cuda:0'),   # indices\n",
    "                          sparse_values.to(dtype=torch.half).to(device='cuda:0'),    # values\n",
    "                          dense_.to(device='cuda:0'),           # rhs_matrix\n",
    "                          bias.to(device='cuda:0'),             # bias\n",
    "                          nrows_sp,         # A_num_rows\n",
    "                          ncols_sp,         # A_num_cols\n",
    "                          ncols_d,          # B_num_cols\n",
    "                          v,                # V\n",
    "                          n,                # N\n",
    "                          m,                # M\n",
    "                          nnz,              # nnz\n",
    "                          0,                # seed\n",
    "                          32,               # mbrow\n",
    "                          4                 # brow\n",
    "                          )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VenomSpmm(torch.nn.Module):\n",
    "    def __init__(self, original: torch.nn.Linear):\n",
    "        super().__init__()\n",
    "        self.bias = original.bias\n",
    "        #self.bias = torch.zeros(original.bias.shape, dtype=original.bias.dtype, device=original.bias.device)\n",
    "\n",
    "        # Convert weights from original module to SrNM\n",
    "        w = VenomSparsifier(n, m, v)(original.weight).wrapped_tensor\n",
    "\n",
    "        self.values = torch.nn.Parameter(w.values)\n",
    "        self.columns = w.columns\n",
    "        self.metadata = w.metadata\n",
    "\n",
    "        self.nrows_sp = w.nrows\n",
    "        self.ncols_sp = w.ncols\n",
    "        self.nnz      = w.nnz\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        flattened_input = torch.flatten(input, start_dim=0, end_dim=-2)\n",
    "\n",
    "        ncols_d  = flattened_input.T.shape[1]\n",
    "        DM, _    = flattened_input.shape\n",
    "        \n",
    "        bias2 = torch.zeros(self.bias.shape, dtype=self.bias.dtype, device=self.bias.device)\n",
    "\n",
    "        output = sparse_dense_mul_dispatch( self.values, \n",
    "                                            self.columns, \n",
    "                                            self.metadata, \n",
    "                                            flattened_input.T, \n",
    "                                            self.nrows_sp, \n",
    "                                            self.ncols_sp,\n",
    "                                            ncols_d, \n",
    "                                            m, \n",
    "                                            n, \n",
    "                                            v, \n",
    "                                            self.nnz, \n",
    "                                            self.bias)\n",
    "        #print(output.shape)\n",
    "        #print(\"bias\", self.bias.shape, self.bias.dtype)\n",
    "        #print(DM)\n",
    "        \n",
    "        \"\"\" if self.bias is not None:\n",
    "            output += self.bias.unsqueeze(0).expand_as(output) \"\"\"\n",
    "        \n",
    "        output = output.reshape((*input.shape[0:-1], -1))[..., :DM]\n",
    "        #output = output.reshape((32,512,1024))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VenomSpmmMasked(torch.nn.Module):\n",
    "    def __init__(self, original: torch.nn.Linear):\n",
    "        super().__init__()\n",
    "        self.bias = original.bias\n",
    "\n",
    "        # Convert weights from original module to SrNM\n",
    "        w = VenomSparsifier(n, m, v)(original.weight).wrapped_tensor\n",
    "\n",
    "        self.values = torch.nn.Parameter(w.values)\n",
    "        self.columns = w.columns\n",
    "        self.metadata = w.metadata\n",
    "\n",
    "        self.nrows_sp = w.nrows\n",
    "        self.ncols_sp = w.ncols\n",
    "        self.nnz      = w.nnz\n",
    "\n",
    "        #self.mask = w.masked\n",
    "        self.dense = w.to_dense()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        flattened_input = torch.flatten(input, start_dim=0, end_dim=-2)\n",
    "\n",
    "        ncols_d  = flattened_input.T.shape[1]\n",
    "        DM, _    = flattened_input.shape\n",
    "\n",
    "        dense_ = flattened_input.T.contiguous()\n",
    "\n",
    "        #print(self.mask.shape, dense_.shape, input.shape)\n",
    "        #output = self.mask@dense_\n",
    "\n",
    "        #output = flattened_input@self.mask.T\n",
    "        #output = (self.mask@flattened_input.T).T\n",
    "        #output = (self.mask@flattened_input.T)\n",
    "        output = input@self.dense.T\n",
    "        \n",
    "        #print(input.shape, flattened_input.shape, self.nrows_sp, self.ncols_sp, output.shape)\n",
    "\n",
    "        #output = output.reshape((*input.shape[0:-1], -1))[..., :DM]\n",
    "    \n",
    "        if self.bias is not None:\n",
    "            output += self.bias.unsqueeze(0).expand_as(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_spmm(mod, weights_to_sparsify):\n",
    "    if isinstance(mod, torch.nn.Linear):\n",
    "        return VenomSpmm(mod)\n",
    "\n",
    "    for name, m in mod.named_children():\n",
    "        if isinstance(m, VenomSpmm):\n",
    "            continue\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            setattr(mod, name, VenomSpmm(m))\n",
    "        elif m is not mod:\n",
    "            linear_to_spmm(m, weights_to_sparsify)\n",
    "\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_masked_spmm(mod, weights_to_sparsify):\n",
    "    if isinstance(mod, torch.nn.Linear):\n",
    "        return VenomSpmmMasked(mod)\n",
    "\n",
    "    for name, m in mod.named_children():\n",
    "        if isinstance(m, VenomSpmmMasked):\n",
    "            continue\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            setattr(mod, name, VenomSpmmMasked(m))\n",
    "        elif m is not mod:\n",
    "            linear_to_masked_spmm(m, weights_to_sparsify)\n",
    "\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_masked(model):\n",
    "    for module_name, module in model.named_modules():\n",
    "        if (\n",
    "                isinstance(module, torch.nn.modules.linear.Linear)\n",
    "                and \"encoder.layer\" in module_name\n",
    "            ):\n",
    "            #print(module_name, module)\n",
    "            #mask = VenomSparsifier.get_random_mask(module.weight, m, v).to(module.weight.device).to(module.weight.dtype)\n",
    "            #module.weight = torch.nn.Parameter(module.weight*mask)\n",
    "            w = VenomSparsifier(n, m, v)(module.weight).wrapped_tensor\n",
    "            module.weight = torch.nn.Parameter(w.to_dense().to(dtype=torch.half))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_to_sparsify = [\n",
    "        module\n",
    "        for module_name, module in sparse_model.named_modules()\n",
    "        if (\n",
    "            isinstance(module, torch.nn.modules.linear.Linear)\n",
    "            and \"encoder.layer\" in module_name\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(low=0, high=100, size=(32, 512))#, dtype=torch.half)\n",
    "input = input.to(device='cuda:0')\n",
    "\n",
    "linear_to_masked(dense_model)\n",
    "\n",
    "sparse_model = sparse_model.to(device='cuda:0').half()\n",
    "sparse_model = linear_to_spmm(sparse_model, weights_to_sparsify)\n",
    "\n",
    "masked_sparse_model = masked_sparse_model.to(device='cuda:0').half()\n",
    "masked_sparse_model = linear_to_masked_spmm(masked_sparse_model, weights_to_sparsify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp_output = sparse_model(input, output_hidden_states=True)\n",
    "output = dense_model(input,  output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_out = dense_model.encoder.layer[0].attention.self.query(output.hidden_states[0])\n",
    "\n",
    "#print(dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' print(\"real output shape\", sparse_out.shape)\\nprint(sparse_out)\\nprint(output.hidden_states[0].shape) '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_out = sparse_model.encoder.layer[0].attention.self.query(output.hidden_states[0])\n",
    "\n",
    "\"\"\" print(\"real output shape\", sparse_out.shape)\n",
    "print(sparse_out)\n",
    "print(output.hidden_states[0].shape) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real output shape torch.Size([32, 512, 1024])\n"
     ]
    }
   ],
   "source": [
    "sparse_masked_out = masked_sparse_model.encoder.layer[0].attention.self.query(output.hidden_states[0])\n",
    "\n",
    "print(\"real output shape\", sparse_masked_out.shape)\n",
    "#print(sparse_masked_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose( sparse_out, sparse_masked_out, atol=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 1024]) torch.Size([32, 512, 1024])\n"
     ]
    }
   ],
   "source": [
    "print( dense_out.shape, sparse_out.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(dense_out, sparse_masked_out, atol=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(dense_out, sparse_out, atol=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dense = dense_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sparse = sparse_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. Revise el código de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener más detalles."
     ]
    }
   ],
   "source": [
    "print( torch.allclose(out_dense[0], out_sparse[0], atol=0.05) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
